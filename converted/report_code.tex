% A latex document created by ipypublish
% outline: ipypublish.templates.outline_schemas\latex_outline.latex.j2
% with segments:
% - standard-standard_packages: with standard nbconvert packages
% - standard-standard_definitions: with standard nbconvert definitions
% - ipypublish-doc_article: with the main ipypublish article setup
% - ipypublish-front_pages: with the main ipypublish title and contents page setup
% - ipypublish-biblio_natbib: with the main ipypublish bibliography
% - ipypublish-contents_output: with the main ipypublish content
% - ipypublish-contents_framed_code: with the input code wrapped and framed
% - ipypublish-glossary: with the main ipypublish glossary
%
%%%%%%%%%%%% DOCCLASS

\documentclass[10pt,parskip=half,
toc=sectionentrywithdots,
bibliography=totocnumbered,
captions=tableheading,numbers=noendperiod]{scrartcl}

%%%%%%%%%%%%

%%%%%%%%%%%% PACKAGES

\usepackage[T1]{fontenc} % Nicer default font (+ math font) than Computer Modern for most use cases
\usepackage{mathpazo}
\usepackage{graphicx}
\usepackage[skip=3pt]{caption}
\usepackage{adjustbox} % Used to constrain images to a maximum size
\usepackage[table]{xcolor} % Allow colors to be defined
\usepackage{enumerate} % Needed for markdown enumerations to work
\usepackage{amsmath} % Equations
\usepackage{amssymb} % Equations
\usepackage{textcomp} % defines textquotesingle
% Hack from http://tex.stackexchange.com/a/47451/13684:
\AtBeginDocument{%
    \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
}
\usepackage{upquote} % Upright quotes for verbatim code
\usepackage{eurosym} % defines \euro
\usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
\usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
\usepackage{fancyvrb} % verbatim replacement that allows latex
\usepackage{grffile} % extends the file name processing of package graphics
                        % to support a larger range
% The hyperref package gives us a pdf with properly built
% internal navigation ('pdf bookmarks' for the table of contents,
% internal cross-reference links, web links for URLs, etc.)
\usepackage{hyperref}
\usepackage{longtable} % longtable support required by pandoc >1.10
\usepackage{booktabs}  % table support for pandoc > 1.12.2
\usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
\usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                            % normalem makes italics be italics, not underlines

\usepackage{translations}
\usepackage{microtype} % improves the spacing between words and letters
\usepackage{placeins} % placement of figures
% could use \usepackage[section]{placeins} but placing in subsection in command section
% Places the float at precisely the location in the LaTeX code (with H)
\usepackage{float}
\usepackage[colorinlistoftodos,obeyFinal,textwidth=.8in]{todonotes} % to mark to-dos
% number figures, tables and equations by section
% fix for new versions of texlive (see https://tex.stackexchange.com/a/425603/107738)
\let\counterwithout\relax
\let\counterwithin\relax
\usepackage{chngcntr}
% header/footer
\usepackage[footsepline=0.25pt]{scrlayer-scrpage}

% bibliography formatting
\usepackage[numbers, square, super, sort&compress]{natbib}
% hyperlink doi's
\usepackage{doi}

    % define a code float
    \usepackage{newfloat} % to define a new float types
    \DeclareFloatingEnvironment[
        fileext=frm,placement={!ht},
        within=section,name=Code]{codecell}
    \DeclareFloatingEnvironment[
        fileext=frm,placement={!ht},
        within=section,name=Text]{textcell}
    \DeclareFloatingEnvironment[
        fileext=frm,placement={!ht},
        within=section,name=Text]{errorcell}

    \usepackage{listings} % a package for wrapping code in a box
    \usepackage[framemethod=tikz]{mdframed} % to fram code

%%%%%%%%%%%%

%%%%%%%%%%%% DEFINITIONS

% Pygments definitions

\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother

% ANSI colors
\definecolor{ansi-black}{HTML}{3E424D}
\definecolor{ansi-black-intense}{HTML}{282C36}
\definecolor{ansi-red}{HTML}{E75C58}
\definecolor{ansi-red-intense}{HTML}{B22B31}
\definecolor{ansi-green}{HTML}{00A250}
\definecolor{ansi-green-intense}{HTML}{007427}
\definecolor{ansi-yellow}{HTML}{DDB62B}
\definecolor{ansi-yellow-intense}{HTML}{B27D12}
\definecolor{ansi-blue}{HTML}{208FFB}
\definecolor{ansi-blue-intense}{HTML}{0065CA}
\definecolor{ansi-magenta}{HTML}{D160C4}
\definecolor{ansi-magenta-intense}{HTML}{A03196}
\definecolor{ansi-cyan}{HTML}{60C6C8}
\definecolor{ansi-cyan-intense}{HTML}{258F8F}
\definecolor{ansi-white}{HTML}{C5C1B4}
\definecolor{ansi-white-intense}{HTML}{A1A6B2}

% commands and environments needed by pandoc snippets
% extracted from the output of `pandoc -s`
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\NormalTok}[1]{{#1}}

% Additional commands for more recent versions of Pandoc
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
\newcommand{\ImportTok}[1]{{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
\newcommand{\BuiltInTok}[1]{{#1}}
\newcommand{\ExtensionTok}[1]{{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}

% Define a nice break command that doesn't care if a line doesn't already
% exist.
\def\br{\hspace*{\fill} \\* }

% Math Jax compatability definitions
\def\gt{>}
\def\lt{<}

\setcounter{secnumdepth}{5}

% Colors for the hyperref package
\definecolor{urlcolor}{rgb}{0,.145,.698}
\definecolor{linkcolor}{rgb}{.71,0.21,0.01}
\definecolor{citecolor}{rgb}{.12,.54,.11}

\DeclareTranslationFallback{Author}{Author}
\DeclareTranslation{Portuges}{Author}{Autor}

\DeclareTranslationFallback{List of Codes}{List of Codes}
\DeclareTranslation{Catalan}{List of Codes}{Llista de Codis}
\DeclareTranslation{Danish}{List of Codes}{Liste over Koder}
\DeclareTranslation{German}{List of Codes}{Liste der Codes}
\DeclareTranslation{Spanish}{List of Codes}{Lista de C\'{o}digos}
\DeclareTranslation{French}{List of Codes}{Liste des Codes}
\DeclareTranslation{Italian}{List of Codes}{Elenco dei Codici}
\DeclareTranslation{Dutch}{List of Codes}{Lijst van Codes}
\DeclareTranslation{Portuges}{List of Codes}{Lista de C\'{o}digos}

\DeclareTranslationFallback{Supervisors}{Supervisors}
\DeclareTranslation{Catalan}{Supervisors}{Supervisors}
\DeclareTranslation{Danish}{Supervisors}{Vejledere}
\DeclareTranslation{German}{Supervisors}{Vorgesetzten}
\DeclareTranslation{Spanish}{Supervisors}{Supervisores}
\DeclareTranslation{French}{Supervisors}{Superviseurs}
\DeclareTranslation{Italian}{Supervisors}{Le autorit\`{a} di vigilanza}
\DeclareTranslation{Dutch}{Supervisors}{supervisors}
\DeclareTranslation{Portuguese}{Supervisors}{Supervisores}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.95}

\lstdefinestyle{mystyle}{
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily,
    breakatwhitespace=false,
    keepspaces=true,
    numbers=left,
    numbersep=10pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    breaklines=true,
    literate={\-}{}{0\discretionary{-}{}{-}},
  postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space},
}

\lstset{style=mystyle}

\surroundwithmdframed[
  hidealllines=true,
  backgroundcolor=backcolour,
  innerleftmargin=0pt,
  innerrightmargin=0pt,
  innertopmargin=0pt,
  innerbottommargin=0pt]{lstlisting}

%%%%%%%%%%%%

%%%%%%%%%%%% MARGINS

 % Used to adjust the document margins
\usepackage{geometry}
\geometry{tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in,
nohead,includefoot,footskip=25pt}
% you can use showframe option to check the margins visually
%%%%%%%%%%%%

%%%%%%%%%%%% COMMANDS

% ensure new section starts on new page
\addtokomafont{section}{\clearpage}

% Prevent overflowing lines due to hard-to-break entities
\sloppy

% Setup hyperref package
\hypersetup{
    breaklinks=true,  % so long urls are correctly broken across lines
    colorlinks=true,
    urlcolor=urlcolor,
    linkcolor=linkcolor,
    citecolor=citecolor,
    }

% ensure figures are placed within subsections
\makeatletter
\AtBeginDocument{%
    \expandafter\renewcommand\expandafter\subsection\expandafter
    {\expandafter\@fb@secFB\subsection}%
    \newcommand\@fb@secFB{\FloatBarrier
    \gdef\@fb@afterHHook{\@fb@topbarrier \gdef\@fb@afterHHook{}}}%
    \g@addto@macro\@afterheading{\@fb@afterHHook}%
    \gdef\@fb@afterHHook{}%
}
\makeatother

% number figures, tables and equations by section
\counterwithout{figure}{section}
\counterwithout{table}{section}
\counterwithout{equation}{section}
\makeatletter
\@addtoreset{table}{section}
\@addtoreset{figure}{section}
\@addtoreset{equation}{section}
\makeatother
\renewcommand\thetable{\thesection.\arabic{table}}
\renewcommand\thefigure{\thesection.\arabic{figure}}
\renewcommand\theequation{\thesection.\arabic{equation}}

    % set global options for float placement
    \makeatletter
        \providecommand*\setfloatlocations[2]{\@namedef{fps@#1}{#2}}
    \makeatother

% align captions to left (indented)
\captionsetup{justification=raggedright,
singlelinecheck=false,format=hang,labelfont={it,bf}}

% shift footer down so space between separation line
\ModifyLayer[addvoffset=.6ex]{scrheadings.foot.odd}
\ModifyLayer[addvoffset=.6ex]{scrheadings.foot.even}
\ModifyLayer[addvoffset=.6ex]{scrheadings.foot.oneside}
\ModifyLayer[addvoffset=.6ex]{plain.scrheadings.foot.odd}
\ModifyLayer[addvoffset=.6ex]{plain.scrheadings.foot.even}
\ModifyLayer[addvoffset=.6ex]{plain.scrheadings.foot.oneside}
\pagestyle{scrheadings}
\clearscrheadfoot{}
\ifoot{\leftmark}
\renewcommand{\sectionmark}[1]{\markleft{\thesection\ #1}}
\ofoot{\pagemark}
\cfoot{}

%%%%%%%%%%%%

%%%%%%%%%%%% FINAL HEADER MATERIAL

% clereref must be loaded after anything that changes the referencing system
\usepackage{cleveref}
\creflabelformat{equation}{#2#1#3}

% make the code float work with cleverref
\crefname{codecell}{code}{codes}
\Crefname{codecell}{code}{codes}
% make the text float work with cleverref
\crefname{textcell}{text}{texts}
\Crefname{textcell}{text}{texts}
% make the text float work with cleverref
\crefname{errorcell}{error}{errors}
\Crefname{errorcell}{error}{errors}

%%%%%%%%%%%%

\begin{document}

    \begin{titlepage}

  \begin{center}

  \vspace*{1cm}

  \Huge\textbf{Final Project}

  \vspace{0.5cm}\LARGE{Face and Digit Classification}

  \vspace{1.5cm}

  \begin{minipage}{0.8\textwidth}
    \begin{center}
    \begin{minipage}{0.39\textwidth}
    \begin{flushleft} \Large
    \emph{\GetTranslation{Author}:}\\Brian Y. Mahesh A.\\\href{mailto:brianyi14@gmail.com ma1700@scarletmail.rutgers.edu}{brianyi14@gmail.com ma1700@scarletmail.rutgers.edu}
    \end{flushleft}
    \end{minipage}
    \hspace{\fill}
    \begin{minipage}{0.39\textwidth}
    \begin{flushright} \Large\emph{\GetTranslation{Supervisors}:} \\
        Abdeslam Boularias
        Aravind S.
    \end{flushright}
    \end{minipage}
    \end{center}
  \end{minipage}

  \vfill

  \begin{minipage}{0.8\textwidth}
  \begin{center}
  \end{center}
  \end{minipage}

  \vspace{0.8cm}
      \LARGE{CS520: Artificial Intelligence}\\
      \LARGE{Rutgers University}\\

  \vspace{0.4cm}

  \today

  \end{center}
  \end{titlepage}

    \begingroup
    \let\cleardoublepage\relax
    \let\clearpage\relax
    \endgroup

\hypertarget{import-and-data-processing}{%
\section{Import and Data Processing}\label{import-and-data-processing}}

For this project, we used NumPy and Pandas modules to import, process,
and transform the raw image data into usable information for model
training. Below is an example of the the raw digit image data along with
the converted image using our convert() method; the raw face image data
is similar in construction. We chose to equate `\#' and `+' pixels with
a value of 1 while any empty pixels were assigned a value of 0. We
storeed most of our data in Panda's Series and DataFrame data structures
along with Python's native list structure.

\label{code:example_sym}
\begin{lstlisting}[aboveskip=5pt,basicstyle=\small,belowskip=5pt,breakindent=0pt,language={},numbers=none,postbreak={},xrightmargin=7pt]
array([['                            ', '0000000000000000000000000000'],
       ['                            ', '0000000000000000000000000000'],
       ['                            ', '0000000000000000000000000000'],
       ['                            ', '0000000000000000000000000000'],
       ['                            ', '0000000000000000000000000000'],
       ['                +++++##+    ', '0000000000000000111111110000'],
       ['        +++++######+###+    ', '0000000011111111111111110000'],
       ['       +##########+++++     ', '0000000111111111111111100000'],
       ['        #######+##          ', '0000000011111111110000000000'],
       ['        +++###  ++          ', '0000000011111100110000000000'],
       ['           +#+              ', '0000000000011100000000000000'],
       ['           +#+              ', '0000000000011100000000000000'],
       ['            +#+             ', '0000000000001110000000000000'],
       ['            +##++           ', '0000000000001111100000000000'],
       ['             +###++         ', '0000000000000111111000000000'],
       ['              ++##++        ', '0000000000000011111100000000'],
       ['                +##+        ', '0000000000000000111100000000'],
       ['                 ###+       ', '0000000000000000011110000000'],
       ['              +++###        ', '0000000000000011111100000000'],
       ['            ++#####+        ', '0000000000001111111100000000'],
       ['          ++######+         ', '0000000000111111111000000000'],
       ['        ++######+           ', '0000000011111111100000000000'],
       ['       +######+             ', '0000000111111110000000000000'],
       ['    ++######+               ', '0000111111111000000000000000'],
       ['    +####++                 ', '0000111111100000000000000000'],
       ['                            ', '0000000000000000000000000000'],
       ['                            ', '0000000000000000000000000000'],
       ['                            ', '0000000000000000000000000000']],
      dtype=object)
\end{lstlisting}

\hypertarget{naive-bayes-model}{%
\section{Naive Bayes Model}\label{naive-bayes-model}}

\hypertarget{algorithm}{%
\subsection{Algorithm}\label{algorithm}}

For our Naive Bayes model, we predict the classification of an image
through the following Naive Bayes assumption:
\(P(Class|Data) = \frac{P(Data|Class)P(Class)}{P(Data)}\). For each
observation, we calculate \(P(Class|Data)\) for each possible class, and
choose the class with the highest probability as our prediction. Since
\(P(Data)\) is a constant, we can ignore it and focus on evaluating
\(P(Data|Class)P(Class)\) when estimating for \(P(Class|Data)\).
\(P(Class)\) is the probability that a certain class appears in a data
set and \(P(Data|Class)\) is the probability that a certain feature
value appears within a certain class. Since we are calculating
\(P(Data|Class)\) through a discrete methodology, there may be many
values for a particular feature that do not appear even once in a class;
this causes \(P(Data|Class) = 0\) and messes up our estimation of
\(P(Class|Data)\). As such, we employ a smoothing method over our model
parameters such that any \(P(Data|Class)\) that equal zero are assigned
a very small value of \(1 \times 10^{-10}\).

\hypertarget{method}{%
\subsection{Method}\label{method}}

We use four methods to train and test our Naive Bayes model,
partition(), feature\_ext(), train\_nb(), and test\_nb(). Partition()
serves to divide a single image of 0s and 1s and divides the image into
the respective feature count and returns an array of features for that
particular image. Feature\_ext() takes these arrays of features returned
from partition() and aggregates how often each feature value appears for
each feature. Feature\_ext() returns a dataframe where the columns
represent each unique feature and the rows represent the total count of
feature values. At that point, it is a simple matter to calculate
P(Data\textbar{}Class) from the dataframe by dividing each feature value
aggregate count by the number of observations in that class. After we
have P(Class) and P(Data\textbar{}Class), we simply take the product for
each class and find the highest product and return that as our
prediction. We use the same training and testing method for both digit
and face classification since our method is robust in feature input and
adjusts the feature selection algorithm accordingly.

\hypertarget{digit-classification}{%
\subsection{Digit Classification}\label{digit-classification}}

We will first look at our model's performance on digit classification
for digits of 0 through 9. Our feature selection is obtained by dividing
a digit image into n x n dimension partitions such that the sum of
colored pixels (1s) within a partition is considered as one feature.
Since each digit image is 28 x 28 pixels, we divided the image into 7 x
7 partitions for a total of 16 features. Unfortunately, using 100\% of
the training set, we got an accuracy of 63.8\%. Being a ways off from
the 70\% cutoff, we decided to narrow the size of each feature to 4 x 4
for a new total of 49 features. By creating smaller partitions, our
features become more precise in capturing the nuances that differ
between each digit. This turned out to be the better choice and
increased our model's overall accuracy from 63.8\% to 74.7\%. The
following dataframe shows the accuracy and time it takes to train and
test our model for various divisions of our training set. As you can see
from the graph below, the accuracy of the model steadily improves the
greater the percentage of the training set is used. This trend makes
sense since the more data the model has on the various ways to draw each
digit, the more accurate the model is when predicting a new test digit
the model hasn't seen before. With regards to time efficiency, the
majority of the time is spent testing the dataset as opposed to training
due to method design. Even though the amount of training data varies
throughout our testing, the test data remains the same at 1000
observations every time. This is why it takes about 130 seconds on
average to fully train and test our model regardless of how much
training data is used.

\begin{table}[H]
\caption{Accuracy and Time of Naive Bayes Digit Classification}\label{tbl:tlabel}
\centering
\begin{adjustbox}{max width=\textwidth}\rowcolors{2}{gray!20}{white}
\begin{tabular}{lrrr}
\toprule
{} &  Mean(Accuracy) (\%) &  Std(Accuracy) (\%) &  Time (sec) \\
Training &                     &                    &             \\
\midrule
10\%      &               58.60 &               1.77 &      127.52 \\
20\%      &               65.12 &               1.85 &      105.45 \\
30\%      &               69.28 &               0.99 &      128.76 \\
40\%      &               71.06 &               1.08 &      120.70 \\
50\%      &               72.58 &               0.98 &      102.83 \\
60\%      &               73.14 &               0.63 &      115.49 \\
70\%      &               73.94 &               0.69 &      111.45 \\
80\%      &               73.80 &               0.43 &      114.23 \\
90\%      &               74.46 &               0.47 &      124.79 \\
100\%     &               74.70 &               0.00 &      114.15 \\
\bottomrule
\end{tabular}

\end{adjustbox}
\end{table}

\begin{figure}[H]\begin{center}\adjustimage{max size={0.9\linewidth}{0.9\paperheight},height=0.23\paperheight}{report_code_files/output_31_0.png}\end{center}\caption{Accuracy at Various Training Set Divisions}\label{fig:flabel}\end{figure}

\hypertarget{face-classification}{%
\subsection{Face Classification}\label{face-classification}}

For face classification, our goal is to determine whether an image is a
face or not. Our feature selection for face classification is similar to
that of digit classification in that we divied a face image into n x n
dimension partitions such that the sum of colored pixels (1s) within a
partition is considered as one feature. Since each face image is 60 x 70
(width x height) pixels, we divided the image into 2 x 2 partitions for
a total of 1050 features. Using 100\% of the training set, we
immediately got an accuracy of 68.7\%. For a Naive Bayes model, we felt
that this accuracy, being 1\% off 70\%, was sufficient in predicting our
face data. The following dataframe shows the accuracy and time it takes
to train and test our model for various divisions of our training set.
Like our Naive Bayes model for digit classification, the accuracy of
this model also improves as more of the training set is used to train
our model. The time efficiency is constant for the same reasons as
explained in digit classification since the same method is used. This
time our testing set is much smaller at 150 observations so the average
time it takes to fully train and test our model is 27 seconds.

\begin{table}[H]
\caption{Accuracy and Time of Naive Bayes Face Classification}\label{tbl:tlabel}
\centering
\begin{adjustbox}{max width=\textwidth}\rowcolors{2}{gray!20}{white}
\begin{tabular}{lrrr}
\toprule
{} &  Mean(Accuracy) (\%) &  Std(Accuracy) (\%) &  Time (sec) \\
Training &                     &                    &             \\
\midrule
10\%      &               51.07 &               0.68 &       24.91 \\
20\%      &               59.20 &               1.29 &       26.03 \\
30\%      &               63.73 &               1.50 &       25.56 \\
40\%      &               66.67 &               0.73 &       26.00 \\
50\%      &               66.93 &               1.37 &       25.90 \\
60\%      &               67.73 &               2.09 &       27.35 \\
70\%      &               68.40 &               0.80 &       27.51 \\
80\%      &               68.53 &               0.65 &       27.39 \\
90\%      &               68.93 &               0.33 &       27.84 \\
100\%     &               68.67 &               0.00 &       27.73 \\
\bottomrule
\end{tabular}

\end{adjustbox}
\end{table}

\begin{figure}[H]\begin{center}\adjustimage{max size={0.9\linewidth}{0.9\paperheight},height=0.23\paperheight}{report_code_files/output_35_0.png}\end{center}\caption{Accuracy at Various Training Set Divisions}\label{fig:flabel}\end{figure}

\hypertarget{perceptron-model}{%
\section{Perceptron Model}\label{perceptron-model}}

\begin{table}[H]
\caption{Accuracy and Time of Perceptron Digit Classification}\label{tbl:tlabel}
\centering
\begin{adjustbox}{max width=\textwidth}\rowcolors{2}{gray!20}{white}
\begin{tabular}{lrlr}
\toprule
{} &  Accuracy (\%) & Standard Deviation &  Time (sec) \\
Training &               &                    &             \\
\midrule
10\%      &         68.28 &              3.86\% &        4.67 \\
20\%      &         74.18 &              4.38\% &        7.04 \\
30\%      &         75.96 &              0.79\% &        9.34 \\
40\%      &         78.16 &              1.71\% &       11.65 \\
50\%      &         76.30 &              3.76\% &       14.06 \\
60\%      &         77.26 &              2.67\% &       16.65 \\
70\%      &         77.04 &              1.23\% &       19.00 \\
80\%      &         77.66 &              2.04\% &       21.05 \\
90\%      &         79.34 &              1.73\% &       24.00 \\
100\%     &         80.40 &              1.78\% &       26.38 \\
\bottomrule
\end{tabular}

\end{adjustbox}
\end{table}

\begin{figure}[H]\begin{center}\adjustimage{max size={0.9\linewidth}{0.9\paperheight},height=0.23\paperheight}{report_code_files/output_41_0.png}\end{center}\caption{Accuracy at Various Training Set Divisions}\label{fig:flabel}\end{figure}

\begin{table}[H]
\caption{Accuracy and Time of Perceptron Face Classification}\label{tbl:tlabel}
\centering
\begin{adjustbox}{max width=\textwidth}\rowcolors{2}{gray!20}{white}
\begin{tabular}{lrlr}
\toprule
{} &  Accuracy (\%) & Standard deviation &  Time (sec) \\
Training &               &                    &             \\
\midrule
10\%      &         68.40 &              5.03\% &        1.16 \\
20\%      &         78.67 &               3.6\% &        1.52 \\
30\%      &         81.60 &               2.0\% &        1.88 \\
40\%      &         83.33 &              3.13\% &        2.16 \\
50\%      &         84.40 &              3.34\% &        2.49 \\
60\%      &         84.13 &              3.99\% &        2.87 \\
70\%      &         84.93 &              2.88\% &        3.20 \\
80\%      &         87.73 &              1.61\% &        3.65 \\
90\%      &         85.73 &              1.72\% &        3.94 \\
100\%     &         87.20 &              2.04\% &        4.31 \\
\bottomrule
\end{tabular}

\end{adjustbox}
\end{table}

\begin{figure}[H]\begin{center}\adjustimage{max size={0.9\linewidth}{0.9\paperheight},height=0.23\paperheight}{report_code_files/output_43_0.png}\end{center}\caption{Accuracy at Various Training Set Divisions}\label{fig:flabel}\end{figure}

\hypertarget{knn-model}{%
\section{KNN Model}\label{knn-model}}

\hypertarget{algorithm}{%
\subsection{Algorithm}\label{algorithm}}

For our third model, we chose to use the K-Nearest Neighbor (KNN) model
to predict the classification of an image. KNN is also a form of
supervised learning where the model is trained on a data set with
labels. KNN predicts the class of an observation by finding the K
nearest neighbors to that observation by a designated ``distance''
metric. Of these K nearest neighbors, we will select the majority class
as our final prediction for that observation. The distance metric for
our model will be the sum of the difference in pixels between two
images. For example, if we have two different images of the digit 3.
After converting both images into 0s and 1s, consider the converted
image as a matrix of 0s and 1s. We then subtract one matrix from the
other, take the squared value to avoid negative values, and sum up all
the remaining 1s as our final distance value. So if any two images are
identical, the distance between the two images would be zero. Our K
nearest neighbors will be the K images that have the smallest distance
with respect to our test image. Usually, an odd number K is selected for
a model with an even number of classes. Since both our digit and image
data have an even number of classes of 10 and 2 respectively, we chose
K=7 as our model parameter.

\hypertarget{method}{%
\subsection{Method}\label{method}}

The methodology for KNN is much simpler than that of our previous
models. Consider one single test observation. If we had to find the K=7
nearest neighbors to this test observation by our distance metric, we
need to find the distance between this test image and every image in the
training set. Our training/testing procedure is wrapped up in one method
that finds the distance between any test image and all the training
images and then chooses the majority class of the 7 classes with the
smallest distance. Note that since a tie is much more likely to occur in
this case as compared to our earlier model metrics, our model handles
tie breakers through Python's list's inherent ordering since we order
our 7 nearest neighbors and then select the class in the first index. We
use a separate training/testing method for digit and face classification
although the key difference lies only within feature selection in the
form of data transformation.

\hypertarget{digit-classification}{%
\subsection{Digit Classification}\label{digit-classification}}

We will first look at our model's performance on digit classification
for digits of 0 through 9. As explained earlier, our features for this
model is the distance metric that is calculated by comparing two images
pixel by pixel. We initially chose k=7 for the number of neighbors when
testing our model. The following dataframe shows the accuracy and time
it takes to train and test our model for various divisions of our
training set. Unfortunately, the model takes a very long time to train
and test since each test observation has to be compared to every single
training observation pixel by pixel; thus, we only took an average
accuracy over three iterations and used a test set of only 50
observations. Do note that while our training set is randomized each
time for every partition, we chose the same 50 observations to test our
model each time for more consistency. The following dataframe shows the
accuracy and time it takes to train and test our model for various
divisions of our training set. Once again, the accuracy of the model
improves as more of the training set is used to train our model with a
peak accuracy of 90\% when we use the entire training set. Looking at
the time efficiency of our model, using only 10\% of the model takes X
seconds while using the whole training set takes the model a full X
hours to train!

\begin{table}[H]
\caption{Accuracy and Time of KNN Face Classification}\label{tbl:tlabel}
\centering
\begin{adjustbox}{max width=\textwidth}\rowcolors{2}{gray!20}{white}
\begin{tabular}{lrrr}
\toprule
{} &  Mean(Accuracy) (\%) &  Std(Accuracy) (\%) &  Time (sec) \\
Training &                     &                    &             \\
\midrule
10\%      &               79.33 &               4.11 &      172.71 \\
20\%      &               87.33 &               1.89 &     1017.01 \\
30\%      &               86.00 &               1.63 &     1574.47 \\
40\%      &               86.67 &               1.89 &     1376.63 \\
50\%      &               88.67 &               2.49 &     1050.52 \\
60\%      &               87.33 &               0.94 &     1526.17 \\
70\%      &               87.33 &               2.49 &     3963.81 \\
80\%      &               87.33 &               1.89 &     2196.54 \\
90\%      &               89.33 &               1.89 &     1514.02 \\
100\%     &               92.00 &               0.00 &     1673.93 \\
\bottomrule
\end{tabular}

\end{adjustbox}
\end{table}

\begin{figure}[H]\begin{center}\adjustimage{max size={0.9\linewidth}{0.9\paperheight},height=0.23\paperheight}{report_code_files/output_54_0.png}\end{center}\caption{Accuracy at Various Training Set Divisions}\label{fig:flabel}\end{figure}

\hypertarget{face-classification}{%
\subsection{Face Classification}\label{face-classification}}

As explained earlier, our features for the face classification KNN model
is the distance metric that is calculated by comparing two images pixel
by pixel. We initially chose k=7 for the number of neighbors for this
model due to its efficacy in digit classification. The following
dataframe shows the accuracy and time it takes to train and test our
model for various divisions of our training set. We once again only took
an average over three iterations due to the nature of KNN training and
testing times, although we opted for a larger test set of size 150 since
our training set of 451 data points is significantly less than the 5000
used in digit classification. Initially, our model only had an accuracy
of 58.67\% when trained upon the full training set. After looking
through the image data again, we noticed that the deciding features of a
face was far more consistent in the eye, nose, and mouth region. We
decided to narrow the focus of our model to only the middle 25 x 30
pixel region and retrained our model accordingly. This time, our model's
accuracy shot up to 74\% from 58.67\% while trained on the full training
set. The following dataframe shows the accuracy and time it takes to
train and test our model for various divisions of our training set.
Unlike the Naive Bayes model, this graph shows an unexpected decrease in
accuracy between 40 and 50\% before improving constantly afterwards.
This can be explained by taking a look at the standard deviations of the
accuracy measurements between the first 10-30\% training set iterations
that tells us whether the mean accuracy measurement may have been
influenced by outlier accuracy iterations. First, note that the standard
deviations during the ``accuracy dip'' are 5.45\% and 4.91\% for 40\%
and 50\% (training set partitions) respectively. Now compare those
standard deviations to the standard deviations measured before the
accuracy dip, which are 8.82\%, 9.02\% and 8.24\%. This allows us to
infer that the accuracy measurements before the accuracy dip may be
assumedly higher than it should be and inflated by an outlier
measurement during one of the iterations. The standard deviation starts
to decrease around 70\%, which makes sense that there is less variation
as more of the training set is sampled, leading to a steady increase in
accuracy from there onwards. Overall, the standard deviations range from
5\% to a shocking 10\% when using 60\% or less of the training set,
which can be explained by the fact that our method only ran three
iterations per training set partition due to runtime restrictions.
Looking at the time efficiency of our model, the average runtime per
iteration is 10 minutes for a total of 5 hours over thirty iterations.

\begin{table}[H]
\caption{Accuracy and Time of KNN Face Classification}\label{tbl:tlabel}
\centering
\begin{adjustbox}{max width=\textwidth}\rowcolors{2}{gray!20}{white}
\begin{tabular}{lrrr}
\toprule
{} &  Mean(Accuracy) (\%) &  Std(Accuracy) (\%) &  Time (sec) \\
Training &                     &                    &             \\
\midrule
10\%      &               56.89 &               8.82 &      161.53 \\
20\%      &               63.11 &               9.02 &      293.37 \\
30\%      &               66.22 &               8.24 &      411.93 \\
40\%      &               64.89 &               5.45 &      631.28 \\
50\%      &               63.11 &               4.91 &      713.95 \\
60\%      &               64.44 &               6.89 &      857.38 \\
70\%      &               67.56 &               3.00 &     1012.93 \\
80\%      &               69.78 &               2.06 &      902.04 \\
90\%      &               72.00 &               1.96 &      434.50 \\
100\%     &               74.00 &               0.00 &      483.65 \\
\bottomrule
\end{tabular}

\end{adjustbox}
\end{table}

\begin{figure}[H]\begin{center}\adjustimage{max size={0.9\linewidth}{0.9\paperheight},height=0.23\paperheight}{report_code_files/output_58_0.png}\end{center}\caption{Accuracy at Various Training Set Divisions}\label{fig:flabel}\end{figure}

\hypertarget{old-methods}{%
\section{Old Methods}\label{old-methods}}

\end{document}
