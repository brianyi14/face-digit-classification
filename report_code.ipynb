{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Classification - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_d_raw = pd.read_csv(\"data/digitdata/trainingimages\",\n",
    "                              skip_blank_lines=False, squeeze=True, header=None)\n",
    "train_lbl_d_raw = pd.read_csv(\"data/digitdata/traininglabels\",\n",
    "                              skip_blank_lines=False, header=None)\n",
    "test_img_d_raw = pd.read_csv(\"data/digitdata/testimages\",\n",
    "                              skip_blank_lines=False, squeeze=True, header=None)\n",
    "test_lbl_d_raw = pd.read_csv(\"data/digitdata/testlabels\",\n",
    "                              skip_blank_lines=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140000,) (5000, 1)\n",
      "(28000,) (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_img_d_raw.shape, train_lbl_d_raw.shape)\n",
    "print(test_img_d_raw.shape, test_lbl_d_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 \n",
       "1                                 \n",
       "2                                 \n",
       "3                                 \n",
       "4                                 \n",
       "5                     +++++##+    \n",
       "6             +++++######+###+    \n",
       "7            +##########+++++     \n",
       "8             #######+##          \n",
       "9             +++###  ++          \n",
       "10               +#+              \n",
       "11               +#+              \n",
       "12                +#+             \n",
       "13                +##++           \n",
       "14                 +###++         \n",
       "15                  ++##++        \n",
       "16                    +##+        \n",
       "17                     ###+       \n",
       "18                  +++###        \n",
       "19                ++#####+        \n",
       "20              ++######+         \n",
       "21            ++######+           \n",
       "22           +######+             \n",
       "23        ++######+               \n",
       "24        +####++                 \n",
       "25                                \n",
       "26                                \n",
       "27                                \n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_d_raw[0:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0000000000000000000000000000\n",
       "1     0000000000000000000000000000\n",
       "2     0000000000000000000000000000\n",
       "3     0000000000000000000000000000\n",
       "4     0000000000000000000000000000\n",
       "5     0000000000000000111111110000\n",
       "6     0000000011111111111111110000\n",
       "7     0000000111111111111111100000\n",
       "8     0000000011111111110000000000\n",
       "9     0000000011111100110000000000\n",
       "10    0000000000011100000000000000\n",
       "11    0000000000011100000000000000\n",
       "12    0000000000001110000000000000\n",
       "13    0000000000001111100000000000\n",
       "14    0000000000000111111000000000\n",
       "15    0000000000000011111100000000\n",
       "16    0000000000000000111100000000\n",
       "17    0000000000000000011110000000\n",
       "18    0000000000000011111100000000\n",
       "19    0000000000001111111100000000\n",
       "20    0000000000111111111000000000\n",
       "21    0000000011111111100000000000\n",
       "22    0000000111111110000000000000\n",
       "23    0000111111111000000000000000\n",
       "24    0000111111100000000000000000\n",
       "25    0000000000000000000000000000\n",
       "26    0000000000000000000000000000\n",
       "27    0000000000000000000000000000\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualization of my conversion in next code block\n",
    "test = train_img_d_raw.copy()\n",
    "test = test.apply(lambda x: x.replace('+', '1'))\n",
    "test = test.apply(lambda x: x.replace('#', '1'))\n",
    "test = test.apply(lambda x: x.replace(' ', '0'))\n",
    "test[0:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts string image (arr) into integer array\n",
    "def convert(arr):\n",
    "    train_img_d_arr = [[0 for col in range(len(arr[0]))] for row in range(len(arr))]\n",
    "    for row in range(len(arr)):\n",
    "        for col in range(len(arr[0])):\n",
    "            if arr[row][col] == '+':\n",
    "                train_img_d_arr[row][col] = 1\n",
    "            if arr[row][col] == '#':\n",
    "                train_img_d_arr[row][col] = 1\n",
    "            if arr[row][col] == ' ':\n",
    "                train_img_d_arr[row][col] = 0\n",
    "    return train_img_d_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing for convert method\n",
    "first_d = convert(train_img_d_raw[0:28])\n",
    "sum(first_d[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divides a 28x28 digit image into 28/feat_size x 28/feat_size matrices\n",
    "def partition(feat_size, arr):\n",
    "    matrix_num = int(28/feat_size)\n",
    "    features = [[0 for col in range(matrix_num)] for row in range(matrix_num)]\n",
    "    for row in range(matrix_num):\n",
    "        for col in range(matrix_num):\n",
    "            for mat_row in range(feat_size):\n",
    "                for mat_col in range(feat_size):\n",
    "                    features[row][col] += arr[mat_row + row*feat_size][mat_col + col*feat_size]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 6, 12, 6], [0, 29, 17, 2], [0, 7, 36, 0], [6, 23, 4, 0]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing for partition method\n",
    "first_d = convert(train_img_d_raw[0:28])\n",
    "partition(7, first_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find features for 2000 digits, last column being the response var\n",
    "def feature_ext(feat_size, data):\n",
    "    features = [[0 for col in range(int((28/feat_size)**2))] for row in range(int(len(data)/28))]\n",
    "    for digit in range(int(len(data)/28)):\n",
    "        # print('iter:', digit)\n",
    "        tmp = partition(feat_size, data[0 + 28*digit:28 + 28*digit])\n",
    "        count = 0\n",
    "        for row in range(int(28/feat_size)):\n",
    "            for col in range(int(28/feat_size)):\n",
    "                features[digit][count] = tmp[row][col]\n",
    "                count += 1    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training method\n",
    "\n",
    "obs_num = 5000                  # pixels*num of observations\n",
    "feat_size = 4                     # pixels per feature that make up X by X matrix\n",
    "feature_num = int((28/feat_size)**2) # number of features\n",
    "\n",
    "train_img_d = convert(train_img_d_raw[0:28*obs_num])\n",
    "features = pd.DataFrame(feature_ext(feat_size, train_img_d))\n",
    "\n",
    "\n",
    "# Add training labels to dataset (1000 default value)\n",
    "tmp = train_lbl_d_raw[:obs_num]\n",
    "tmp.rename(columns={0:int((28/feat_size)**2)}, inplace=True)\n",
    "features = pd.concat([features, tmp], axis=1)\n",
    "\n",
    "# P(Class)\n",
    "p_class = features.iloc[:, -1].value_counts()\n",
    "p_class.sort_index(inplace=True)\n",
    "p_class = p_class/obs_num\n",
    "\n",
    "# P(Data | Class)\n",
    "final = []\n",
    "for dig in range(10):\n",
    "    p_data_class = pd.DataFrame([[0 for col in range(feature_num*1)] for row in range(feat_size**2 + 1)])\n",
    "    for feature in range(feature_num):\n",
    "        tmp = features.loc[features.iloc[:,-1] == dig][feature].value_counts()\n",
    "        for feature_val in tmp.index:\n",
    "            p_data_class[feature][feature_val] = tmp[feature_val]\n",
    "    p_data_class = p_data_class / features.iloc[:, -1].value_counts().sort_index()[dig]\n",
    "    p_data_class.columns = pd.MultiIndex.from_product([[dig], range(feature_num)], names=['Digit', 'Feature'])\n",
    "    if dig == 0:\n",
    "        final = p_data_class\n",
    "    else:\n",
    "        final = final.join(p_data_class)\n",
    "p_data_class = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classified correct: 0.747\n"
     ]
    }
   ],
   "source": [
    "# Testing method\n",
    "\n",
    "obs_num = 1000                        # pixels*num of observations\n",
    "feat_size = 4                        # pixels per feature that make up X by X matrix\n",
    "feature_num = int((28/feat_size)**2) # number of features\n",
    "\n",
    "observation = feature_ext(feat_size, convert(test_img_d_raw[0:28*obs_num]))\n",
    "\n",
    "p_data_class = p_data_class.replace(0, 0.00000000001) # Removes 0% probabilities\n",
    "\n",
    "test_lbl_d_raw[:obs_num] # test set\n",
    "\n",
    "total_correct = 0\n",
    "for obs, num in zip(observation, range(obs_num)):\n",
    "    prob_f = []\n",
    "    correct = 1\n",
    "    for dig in range(10):\n",
    "        tmp = p_data_class.iloc[:, p_data_class.columns.get_level_values(0)==dig]\n",
    "        prob = []\n",
    "        for feat in range(feature_num):\n",
    "            prob.append(tmp.iloc[:, feat][obs[feat]])\n",
    "        prob_f.append(np.prod(prob)*p_class[dig])\n",
    "    if test_lbl_d_raw[0][num] == prob_f.index(max(prob_f)):\n",
    "        correct = True\n",
    "        total_correct += 1\n",
    "    else:\n",
    "        correct = False\n",
    "print('Total classified correct:', total_correct/obs_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_f_raw = pd.read_csv(\"data/facedata/facedatatrain\",\n",
    "                              skip_blank_lines=False, squeeze=True, header=None)\n",
    "train_lbl_f_raw = pd.read_csv(\"data/facedata/facedatatrainlabels\",\n",
    "                              skip_blank_lines=False, header=None)\n",
    "test_img_f_raw = pd.read_csv(\"data/facedata/facedatatest\",\n",
    "                              skip_blank_lines=False, squeeze=True, header=None)\n",
    "test_lbl_f_raw = pd.read_csv(\"data/facedata/facedatatestlabels\",\n",
    "                              skip_blank_lines=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31570,) (451, 1)\n",
      "(10500,) (150, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_img_f_raw.shape, train_lbl_f_raw.shape)\n",
    "print(test_img_f_raw.shape, test_lbl_f_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divides a 28x28 digit image into 28/feat_size x 28/feat_size matrices\n",
    "def partition(feat_size, arr):\n",
    "    features = [[0 for col in range(30)] for row in range(35)]\n",
    "    for row in range(35):\n",
    "        for col in range(30):\n",
    "            for mat_row in range(2):\n",
    "                for mat_col in range(2):\n",
    "                    features[row][col] += arr[mat_row + row*feat_size][mat_col + col*feat_size]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find features for 2000 digits, last column being the response var\n",
    "def feature_ext(feat_size, data):\n",
    "    features = [[0 for col in range(1050)] for row in range(int(len(data)/70))]\n",
    "    for digit in range(int(len(data)/70)):\n",
    "        # print('iter:', digit)\n",
    "        tmp = partition(feat_size, data[0 + 70*digit:70 + 70*digit])\n",
    "        count = 0\n",
    "        for row in range(35):\n",
    "            for col in range(30):\n",
    "                features[digit][count] = tmp[row][col]\n",
    "                count += 1    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training method\n",
    "\n",
    "obs_num = 451                  # pixels*num of observations\n",
    "feat_size = 2                     # pixels per feature that make up X by X matrix\n",
    "feature_num = 1050 # number of features\n",
    "\n",
    "train_img_f = convert(train_img_f_raw[0:70*obs_num])\n",
    "features = pd.DataFrame(feature_ext(feat_size, train_img_f))\n",
    "\n",
    "\n",
    "# Add training labels to dataset (1000 default value)\n",
    "tmp = train_lbl_f_raw[:obs_num]\n",
    "tmp.rename(columns={0:1050}, inplace=True)\n",
    "features = pd.concat([features, tmp], axis=1)\n",
    "\n",
    "# P(Class)\n",
    "p_class = features.iloc[:, -1].value_counts()\n",
    "p_class.sort_index(inplace=True)\n",
    "p_class = p_class/obs_num\n",
    "\n",
    "# P(Data | Class)\n",
    "final = []\n",
    "for classif in range(2):\n",
    "    p_data_class = pd.DataFrame([[0 for col in range(feature_num*1)] for row in range(feat_size**2 + 1)])\n",
    "    for feature in range(feature_num):\n",
    "        tmp = features.loc[features.iloc[:,-1] == classif][feature].value_counts()\n",
    "        for feature_val in tmp.index:\n",
    "            p_data_class[feature][feature_val] = tmp[feature_val]\n",
    "    p_data_class = p_data_class / features.iloc[:, -1].value_counts().sort_index()[classif]\n",
    "    p_data_class.columns = pd.MultiIndex.from_product([[classif], range(feature_num)], names=['Class', 'Feature'])\n",
    "    if classif == 0:\n",
    "        final = p_data_class\n",
    "    else:\n",
    "        final = final.join(p_data_class)\n",
    "p_data_class = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classified correct: 0.6866666666666666\n"
     ]
    }
   ],
   "source": [
    "# Testing method\n",
    "\n",
    "obs_num = 150                        # pixels*num of observations\n",
    "feat_size = 2                        # pixels per feature that make up X by X matrix\n",
    "feature_num = 1050 # number of features\n",
    "\n",
    "observation = feature_ext(feat_size, convert(test_img_f_raw[0:70*obs_num]))\n",
    "\n",
    "p_data_class = p_data_class.replace(0, 0.00000000001) # Removes 0% probabilities\n",
    "\n",
    "test_lbl_f_raw[:obs_num] # test set\n",
    "\n",
    "total_correct = 0\n",
    "for obs, num in zip(observation, range(obs_num)):\n",
    "    prob_f = []\n",
    "    correct = 1\n",
    "    for classif in range(2):\n",
    "        tmp = p_data_class.iloc[:, p_data_class.columns.get_level_values(0)==classif]\n",
    "        prob = []\n",
    "        for feat in range(feature_num):\n",
    "            prob.append(tmp.iloc[:, feat][obs[feat]])\n",
    "        prob_f.append(np.prod(prob)*p_class[classif])\n",
    "    if test_lbl_f_raw[0][num] == prob_f.index(max(prob_f)):\n",
    "        correct = True\n",
    "        total_correct += 1\n",
    "    else:\n",
    "        correct = False\n",
    "print('Total classified correct:', total_correct/obs_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Classification - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_d_raw = pd.read_csv(\"data/digitdata/trainingimages\",\n",
    "                              skip_blank_lines=False, squeeze=True, header=None)\n",
    "train_lbl_d_raw = pd.read_csv(\"data/digitdata/traininglabels\",\n",
    "                              skip_blank_lines=False, header=None)\n",
    "test_img_d_raw = pd.read_csv(\"data/digitdata/testimages\",\n",
    "                              skip_blank_lines=False, squeeze=True, header=None)\n",
    "test_lbl_d_raw = pd.read_csv(\"data/digitdata/testlabels\",\n",
    "                              skip_blank_lines=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts string image (arr) into integer array\n",
    "def convert(arr):\n",
    "    train_img_d_arr = [[0 for col in range(len(arr[0]))] for row in range(len(arr))]\n",
    "    for row in range(len(arr)):\n",
    "        for col in range(len(arr[0])):\n",
    "            if arr[row][col] == '+':\n",
    "                train_img_d_arr[row][col] = 1\n",
    "            if arr[row][col] == '#':\n",
    "                train_img_d_arr[row][col] = 1\n",
    "            if arr[row][col] == ' ':\n",
    "                train_img_d_arr[row][col] = 0\n",
    "    return train_img_d_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_num = 50 # train set num\n",
    "\n",
    "tmp = convert(train_img_d_raw[0:28*obs_num])\n",
    "train_dig_df = []\n",
    "for dig in range(obs_num):\n",
    "    train_dig_df.append(pd.DataFrame(tmp[0 + 28*dig:28 + 28*dig]))\n",
    "\n",
    "test_obs = 10 # test set num\n",
    "\n",
    "tmp2 = convert(test_img_d_raw[0:28*test_obs])\n",
    "test_dig_df = []\n",
    "for dig in range(test_obs):\n",
    "    test_dig_df.append(pd.DataFrame(tmp2[0 + 28*dig:28 + 28*dig]))\n",
    "\n",
    "\n",
    "correct = 0\n",
    "for obs in range(test_obs):\n",
    "    k = []\n",
    "    for img in train_dig_df:\n",
    "        k.append(((test_dig_df[obs] - img)**2).sum().sum())\n",
    "    k = pd.DataFrame(k)\n",
    "    k = k[0].sort_values()[0:7]\n",
    "    maj_class = []\n",
    "\n",
    "\n",
    "    for i in k.index:\n",
    "        maj_class.append(train_lbl_d_raw[0][i])\n",
    "    maj_val = pd.DataFrame(maj_class)[0].value_counts().index[0]\n",
    "    if maj_val == test_lbl_d_raw[0][obs]:\n",
    "        correct += 1\n",
    "\n",
    "correct / test_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_f_raw = pd.read_csv(\"data/facedata/facedatatrain\",\n",
    "                              skip_blank_lines=False, squeeze=True, header=None)\n",
    "train_lbl_f_raw = pd.read_csv(\"data/facedata/facedatatrainlabels\",\n",
    "                              skip_blank_lines=False, header=None)\n",
    "test_img_f_raw = pd.read_csv(\"data/facedata/facedatatest\",\n",
    "                              skip_blank_lines=False, squeeze=True, header=None)\n",
    "test_lbl_f_raw = pd.read_csv(\"data/facedata/facedatatestlabels\",\n",
    "                              skip_blank_lines=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5866666666666667"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_num = 451 # train set num\n",
    "\n",
    "tmp = convert(train_img_f_raw[0:70*obs_num])\n",
    "train_face_df = []\n",
    "for face in range(obs_num):\n",
    "    train_face_df.append(pd.DataFrame(tmp[0 + 70*face:70 + 70*face]))\n",
    "\n",
    "test_obs = 150 # test set num\n",
    "\n",
    "tmp2 = convert(test_img_f_raw[0:70*test_obs])\n",
    "test_face_df = []\n",
    "for face in range(test_obs):\n",
    "    test_face_df.append(pd.DataFrame(tmp2[0 + 70*face:70 + 70*face]))\n",
    "\n",
    "\n",
    "correct = 0\n",
    "for obs in range(test_obs):\n",
    "    k = []\n",
    "    for img in train_face_df:\n",
    "        k.append(((test_face_df[obs] - img)**2).sum().sum())\n",
    "    k = pd.DataFrame(k)\n",
    "    k = k[0].sort_values()[0:7]\n",
    "    #print('k', k)\n",
    "    maj_class = []\n",
    "\n",
    "    for i in k.index:\n",
    "        maj_class.append(train_lbl_f_raw[0][i])\n",
    "    maj_val = pd.DataFrame(maj_class)[0].value_counts().index[0]\n",
    "    #print(maj_val, test_lbl_f_raw[0][obs])\n",
    "    if maj_val == test_lbl_f_raw[0][obs]:\n",
    "        correct += 1\n",
    "\n",
    "correct / test_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_num = 451 # train set num\n",
    "\n",
    "tmp = convert(train_img_f_raw[0:70*obs_num])\n",
    "train_face_df = []\n",
    "for face in range(obs_num):\n",
    "    train_face_df.append(pd.DataFrame(tmp[25 + 70*face:50 + 70*face]).iloc[:, 15:45])\n",
    "\n",
    "test_obs = 150 # test set num\n",
    "\n",
    "tmp2 = convert(test_img_f_raw[0:70*test_obs])\n",
    "test_face_df = []\n",
    "for face in range(test_obs):\n",
    "    test_face_df.append(pd.DataFrame(tmp2[25 + 70*face:50 + 70*face]).iloc[:, 15:45])\n",
    "\n",
    "\n",
    "correct = 0\n",
    "for obs in range(test_obs):\n",
    "    k = []\n",
    "    for img in train_face_df:\n",
    "        k.append(((test_face_df[obs] - img)**2).sum().sum())\n",
    "    k = pd.DataFrame(k)\n",
    "    k = k[0].sort_values()[0:7]\n",
    "    #print('k', k)\n",
    "    maj_class = []\n",
    "\n",
    "    for i in k.index:\n",
    "        maj_class.append(train_lbl_f_raw[0][i])\n",
    "    maj_val = pd.DataFrame(maj_class)[0].value_counts().index[0]\n",
    "    if maj_val == test_lbl_f_raw[0][obs]:\n",
    "        correct += 1\n",
    "\n",
    "correct / test_obs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
